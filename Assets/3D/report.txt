

We can view every pixel as a little voxel - with some spatial and temporal extent. Visualzing this cube however only reveals the outer voxels. It is hard to gleam any information from this. To remedy this, we can visualze particular aspects of a video instead. If $f(x, y, t)$ is our video we can define a new function $c(x, y, t)$ to he plugged into the visualizer instead. Consider a simple function, which visualzes every 10th frame of the video: 

$$c(x, y, t) = \delta_{t % 10, 0} f(x, y, t)$$

Temporal slices

Edge detection:

Blurring kernels

Besides traditional image filters, we can now extend these filters to the temporal domain. Eg:

$c(x, y, t) = \Delta_tt f(x, y, t)$

The visualization shows all temporal edges in the video. This reveleals moving objects in a scene more clearly.




Most of this report will discuss these maps and visualiz them. However, given their 3 dimensional nature, they are best viewed interactively. A supplementary webpage is available at... where these cubes can be viewed interactively.

Algorithm overview:

Mapping function

The mapping function is implemented 

First, all video frames are loaded into a 3D memory buffer on the GPU. Then, a shader is run which reads from this 3D buffer and writes into a new 3D buffer. 

For iterative algorithms (eg, applying a median filter after the first map), we can reuse these same buffers to save GPU memory.



Eg, we can visualize the gradients of the colors

c'(x, y, t) = |Grad_xx c(x, y, t) + Grad_yy c(x, y, t)| * c'



The vidoes were processed at 340x240 resolution. At 30 frames per second this means there are 2.448.000 voxels in a second. To visualize 5 seconds of film requires 12.240.000 voxels. If each voxe

This is even on modern day hardware a lot of triangles to render. Luckily, we can easily cull away a large amount of voxels:

1. Every voxel that is fully transparent
2. Every voxel that s fully surounded by fully opaque voxels.

$c(x, y, t)_{\alpha} > 0$
$min_{N}(c(x + \delta_n x, y + \delta_n y, t + \delta_n t)) < 1$


Using this information, we now spawn one voxel for every position that needs it. TC Particles was used.




OIT?

Transparancies are traditionally hard to render, because their blending function is not order independent. Sorting objects correctly can be expensive or even impossible depending on the geometry. To support transparancies an implementation of OIT by bla et al was made. This approximates alpha blending by keeping an offscreen buffer of... The approximation is generally of high quality, and since most visualizations used here produce results that are near binary the effect is convincing.




3D printing

Now that we can create interesting geometric shapes from video, there's an oppurtunity to manifest one of the videos into real life. Of course, not every map $c(x, y, t)$ will result in a geometry that can be printed (eg. it might have disjoints parts).

Some manual post processing was done. This was then fabricated in real life.